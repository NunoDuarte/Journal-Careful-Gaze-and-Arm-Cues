\section{Introduction}

\lettrine{C}{ontainers} such as the ones that carry liquids, like cups, glasses, mugs, produce a response on the human when transporting depending on the fillness level. Mayer et al. \cite{mayer_walking_2012} provides an example of walking with a mug filled with coffee, a typical challenge to anyone in academia. They've found that humans try to solve the issue of spilling by either estimating the frequency of sloshing of the liquid and counteract the resonance to suppress it, or by simply being pro-active and careful during manipulation. The authors justify the reason for picking one of the approach down to individual preference, however we argue that most would resort to the latter option as is the one that requires the least effort and with less accidents. 

% neuroscience
\cite{alaerts_force_2010} Observing lifting objects of different weights modulate M1, primary motor cortex, in a muscle-specific way.  The higher the M1 excitability is, the heavier is the object. It may contribute, at least partly, to the observer's ability to infer the weight of the object. 
\cite{senot_effect_2011}
predominance of kinematic cues over intrinsic object properties in coding force required to execute an observed lifting action. 
\cite{lindemann_grasping_2011} biological grasping actions modulated the observer's attention

As such, this paper aims at providing an in depth scope of the manipulation strategies for cups filled with water or completely empty. As it provides two opposite scenarios with contrasting levels of difficulty. The purpose of this analysis is so that it can provide useful features that robots can take advantage. 

In a factory plant, robots can understand inherent properties of objects, such as fragility or breakableness by observing how humans interact with it, or in an elderly home, where a robot caretaker needs to adapt to the motor capabilities of each senior resident. 

% soa

\cite{hamilton_kinematic_2007} \cite{sciutti_understanding_2014} subjects can reach a performance in weight recognition from robot observation comparable to that obtained during human observations with no need of training. Human explicit kinematic whether it is a human or a robot. However the robot must exhibit familiar motor behaviours to the human. 
\cite{sciutti_development_2019} At age 6 we can estimate difference in weight by observing different videos of objects. Features important to estimate weight are duration and absolute velocity. 

\cite{mavridis_review_2015} review of non-verbal cues. 
\cite{duarte_action_2018} human non-verbal cues to decode action intention, and when incorporating onto a robot, it provides similar information to read the robot's intention." 
\cite{palinko_communicative_2015} passing an object relies on the non-verbal communication associated to the passer's motion. Ask the human's to judge the weight of the object
the robot's ability to anticipate human actions requires knowledge of the motor and cognitive bases of human-human interaction \cite{sciutti_humanizing_2018} \cite{admoni_robot_2016} 

there have been many works on robot learning from human demonstrations \cite{ravichandar_recent_2020}

minimum-jerk acceleration and deceleration phase of arm motions \cite{fligge_minimum_2012}

\cite{Medina2016} only focused on the handover, not the manipulation/transportation. The robot waits for the load share to pass a certain, hand-tuned, human based, threshold.  and studying the impact of human non-verbal cues on the location of the handover \cite{kato_where_2019} and the effects of the objects' weight \cite{hansen_humanhuman_2017}

recent research has looked into the kinematic motion of manipulating full and empty cups \cite{lastrico_careful_2021}. However their focus was on generating motions that reflect the different strategies and not on utilizing this features for human-robot interactions. 

% structure of the paper
We start by defining the human-human interaction scenario detailed in Section \ref{sec:human}, describing the experiments, the sensor information collected, and the data chosen to analyse the handover of cups. The human non-verbal cues extracted from the HHI dataset are employed on computational models of kinematic approaches of handover of empty and full of water cups (Section \ref{sec:model}). Two computational models are mentioned, one novel and one previously proposed, that from the handover trajectories extract features to express the kinematic strategies of manipulating empty and full of water cups. The presented classifier allows for a fair metric of both models performance. The accuracy of each model is measured on how well it can distinguish handovers of empty cups as natural manipulations (not careful), and handover of water filled cups as a careful manipulation. In Section \ref{sec:results} it presents additional classification results in order to understand the impact of different types of cups, as well as, other datasets of human handovers with unknown cups, and unknown participants. The developed computational model with the best classification accuracy is incorporated in a robotic controller in Section \ref{sec:robot}. The model runs in a human-in-the-loop system which provides the robot with information on the cup or object interacted by the human as to adapt its motor control approach when grasping or manipulating. The Section \ref{sec:conc} we discuss the findings from our analysis of the human-human data, classification accuracy of the computational models, and human-robot experiments, and finish by outlining future work proposals.  

